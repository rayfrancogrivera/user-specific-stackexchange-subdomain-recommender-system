{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Specific StackExhange Subdomain Recommender System\n",
    "LT2: Marvin V. Belina, Kris Gerald R. del Norte, Ray Franco G. Rivera, Ren Christian M. Santos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to everything, let's import the dependencies of our notebook. At the start of an ElasticMapReduce (EMR) instance with PySpark kernel, we initialize the SparkSession and SparkContext by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355da28e87ba43afbe2381ffe057d5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1577521624822_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-8-183.ap-northeast-1.compute.internal:20888/proxy/application_1577521624822_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-14-56.ap-northeast-1.compute.internal:8042/node/containerlogs/container_1577521624822_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f0d6c322b00>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c0579bc40347c4bd74e7c076670739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=yarn appName=livy-session-0>"
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the kernel lacks some of the libraries required for this project. We install the following libraries using the `sc.install_pypi_package` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35df5f8838e742a79a1042338d37b8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading https://files.pythonhosted.org/packages/72/5c/ec84c7ec49fde2c3b0d885ecae4504fa40fc77fef7684e9f2939c50f9b94/s3fs-0.4.0-py3-none-any.whl\n",
      "Collecting boto3>=1.9.91\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/01/1c749dc1bca8dda969f5fe0ba16fa6d24c6bd96572d118f790773c54a636/boto3-1.10.45-py2.py3-none-any.whl (128kB)\n",
      "Collecting botocore>=1.12.91\n",
      "  Downloading https://files.pythonhosted.org/packages/96/22/9f8201d900956e57a9811e1b1c91c9f76c87487c76f636c2df1ce8379c38/botocore-1.13.45-py2.py3-none-any.whl (5.9MB)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/1f/7028dacd3c28f34ce48130aae73a88fa5cc27b6b0e494fcf2739f7954d9d/fsspec-0.6.2-py3-none-any.whl (62kB)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs) (0.9.4)\n",
      "Collecting python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version >= \"3.4\"\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore>=1.12.91->s3fs) (1.12.0)\n",
      "Installing collected packages: python-dateutil, docutils, urllib3, botocore, s3transfer, boto3, fsspec, s3fs\n",
      "Successfully installed boto3-1.10.45 botocore-1.13.45 docutils-0.15.2 fsspec-0.6.2 python-dateutil-2.8.1 s3fs-0.4.0 s3transfer-0.2.1 urllib3-1.25.7"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package('s3fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89276e05b2c43e38032f185eeae8ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unicodecsv\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
      "Building wheels for collected packages: unicodecsv\n",
      "  Building wheel for unicodecsv (setup.py): started\n",
      "  Building wheel for unicodecsv (setup.py): finished with status 'done'\n",
      "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp36-none-any.whl size=10767 sha256=e752a1b26934ae35a1c9e86df943eabdd583ef909755317694ceb458da199c4d\n",
      "  Stored in directory: /var/lib/livy/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
      "Successfully built unicodecsv\n",
      "Installing collected packages: unicodecsv\n",
      "Successfully installed unicodecsv-0.14.1"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package('unicodecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e19255e851418ebdc06f18028c509a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /mnt/tmp/1577522008925-0/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-0.25.3"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package('pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have downloaded and installed all the dependencies, we now import them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24052acf5c194ca0b8689463b561d229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "import s3fs\n",
    "import re\n",
    "import os, glob\n",
    "import string\n",
    "import unicodecsv as csv\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer, QuantileDiscretizer, Bucketizer\n",
    "from pyspark.sql.functions import min, max, col, collect_set, size\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackExchange is a Q&A forum that empowers users to tap knowledge through an easily accessible platform. However, given the limited functionality of their website and the vast amount of subdomains available, it hampers the growth of knowledge sharing and the website by making it difficult for users to discover new content that would be interesting for them. With the culture that StackExchange promotes, and considering the potential for a specific user to learn and grow, it would be beneficial to create a recommendation of topics tailored to what the user likes, to help them further expand their knowledge base. In this project, the team wrangled ~60GB worth of user-contributed content gathered across 162 subdomains from the website, StackExchange. This was then used to create two (2) implementations of a recommender system using Frequent Itemset Mining (FIM) & Association Rules (AR) and User-based Collaborative Filtering through the cloud computing service, Amazon Web Services (AWS). The team was able to create two (2) recommender systems that are beneficial for two (2) endpoints -- website owners and users. Website owners could use the recommender system to generate more web traffic for their specific subdomains and users can easily discover new content through the user-specific recommender system that we have created. The approach that the team has created can also be applied to various industries such as e-commerce, social media and any other industry that has a rich database of user-item transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackExchange is an aggregator website of various subdomains that operate similar to a question-and-answer (Q&A) forum. The website is modelled after the initial site StackOverflow, primarily focused on computer programming questions. With StackExchange, the scope of topics, questions and discussions are vaster, making it harder to discover new content that is most relevant to a user’s interest. Even though the home page shows the top questions based on “hotness”, these recommendations are not user-specific. This led the team to ask the question -- \"How do we make it easier for users of StackExchange to discover new content that would suit their interests?\" Currently, there’s no built-in system to recommend new subdomains that are specific to a user. Being able to create a user-specific recommender system would be beneficial for the owner (e.g. more website traffic) and users (e.g. content discovery) of the website.\n",
    "\n",
    "In this project, the team proposes to create two (2) implementations of a recommender system using:\n",
    "1. Frequent Itemset Mining; and\n",
    "2. User-based Collaborative Filtering\n",
    "\n",
    "For the implementation of FIM, we will process the gathered data to create an itemset of visited subdomains for each specific user. Found frequent item-sets indicate good combinations of subdomains that are frequented together by users. In addition, we can also establish associations between these subdomains to further our analysis.\n",
    "\n",
    "For the implementation of a User-based Collaborative Filtering, we will be creating a utility matrix with the users as rows and subdomains as the columns. The ratings of each user for a certain subdomain will be based on how much the user frequents the subdomain. We plan to measure this through comment counts. With this information, we can recommend new subdomains to a certain user based on the most similar users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this project was collected from the StackExchange dataset available at https://archive.org/details/stackexchange. The dataset contains ~60GB worth of user-contributed content across 162 subdomains. Each subdomain dump contains seven (7) XML files – badges.xml, comments.xml, posts.xml, posthistory.xml, postlinks.xml users.xml, and votes.xml.\n",
    "\n",
    "The full schema of each .xml file can be found at https://ia800107.us.archive.org/27/items/stackexchange/readme.txt.\n",
    "\n",
    "For this particular project, we would only be needing data from the comments.xml file of each subdomain. In total, we will be using 16.5 million user comments from about 248,000 unique users across 162 subdomains to create our recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with xml files, we create a function that will take as an input the subdomain name and read its contents as a string. After which, we then parse the string as an xml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcd7634dac64ec0a61a8facbc561e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse xml\n",
    "def parsexml(fp):\n",
    "    f = sc.textFile('s3://bdcc-rrivera-2020/stackexchange/actual/' + fp + '.stackexchange.com/Comments.xml').collect()\n",
    "    root = ET.fromstring(' '.join(f))\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the list of all subdomain names from `s3://bdcc-rrivera-2020/stackexchange/actual/`, which is the path where all the stackexchange subdomains archive resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9899ba05032e4a42999a75cd91266f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting list of subdomain names\n",
    "# key = 'mysecretkey'\n",
    "# secret = 'mysecretid'\n",
    "# fs = s3fs.S3FileSystem(key=key, secret=secret)\n",
    "# fps3 = fs.ls('s3://bdcc-rrivera-2020/stackexchange/actual/')\n",
    "\n",
    "# filepaths = []\n",
    "\n",
    "# for e in range(len(fps3)):\n",
    "#     try:\n",
    "#         m = re.findall('actual/(.+).stackexchange.com', fps3[e])[0]\n",
    "#         filepaths.append(m)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `parsexml` function we created earlier, we parse each row (comment) of a subdomain and save it as a `csv` file. This will allow us to easily read our big data though PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324085c1e2234776b1374331fe4b667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge all comments per subdomain and save to csv\n",
    "\n",
    "# cols = ['Id', 'PostId', 'Score', 'Text', 'CreationDate', 'UserId', 'SubDomain']\n",
    "\n",
    "# for fp in filepaths:\n",
    "#     commentlist = []\n",
    "#     root = parsexml(fp)\n",
    "#     for i in range(len(root)):\n",
    "#         root[i].attrib['SubDomain'] = fp # Add subdomain name as key-value pair\n",
    "#         if 'UserDisplayName' in root[i].attrib.keys():\n",
    "#             del root[i].attrib['UserDisplayName']\n",
    "#         if cols == list(root[i].attrib.keys()):\n",
    "#             del root[i].attrib['Text']\n",
    "#             commentlist.append(root[i].attrib)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#     keys = commentlist[0].keys()\n",
    "#     with fs.open('s3://bdcc-rrivera-2020/stackexchange/actual/csv/' + fp + '.csv', 'wb') as output_file:\n",
    "#         dict_writer = csv.DictWriter(output_file, keys)\n",
    "#         dict_writer.writeheader()\n",
    "#         dict_writer.writerows(commentlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark can read the csv files that we have created as one big file using the function `spark.read.csv`. The function will return a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f697c3fb4dd4467a7d8feb99b432d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading all csv files\n",
    "df = spark.read.csv('s3://bdcc-rrivera-2020/stackexchange/actual/csv/*.csv', \n",
    "                    header=True,\n",
    "                    schema=\"\"\"\n",
    "                    Id FLOAT,\n",
    "                    PostId FLOAT,\n",
    "                    Score FLOAT,\n",
    "                    CreationDate STRING,\n",
    "                    UserId FLOAT,\n",
    "                    SubDomain STRING\n",
    "                    \"\"\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the files, let's look at how many rows we have for the whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83305dda8387469a9d04ff27fc414d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16530530"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total count of rows (comments) of 16,530,530."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f90206510042f18f0dcd8a95e6d1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+------+-----------+\n",
      "| Id|PostId|Score|        CreationDate|UserId|  SubDomain|\n",
      "+---+------+-----+--------------------+------+-----------+\n",
      "|1.0|  19.0|  0.0|2009-10-30T20:54:...|  24.0|electronics|\n",
      "|2.0|  19.0|  0.0|2009-10-30T21:18:...|  12.0|electronics|\n",
      "|3.0|  46.0|  0.0|2009-10-31T00:43:...|  24.0|electronics|\n",
      "|4.0|  46.0|  2.0|2009-11-01T02:25:...|  26.0|electronics|\n",
      "|5.0|  46.0|  1.0|2009-11-01T03:32:...|  26.0|electronics|\n",
      "+---+------+-----+--------------------+------+-----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out the first five (5) rows of our dataframe, we can see that it has five (5) columns namely Id, PostId, Score, CreationDate, UserId, and Subdomain. Let's drop NaNs and check the column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74b9a00ba7342c1a8aadb380c01c9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping NaNs\n",
    "# df = df.withColumn('Id', df['Id'].astype('float'))\n",
    "# df = df.withColumn('PostId', df['PostId'].astype('float'))\n",
    "# df = df.withColumn('Score', df['Score'].astype('float'))\n",
    "# df = df.withColumn('UserId', df['UserId'].astype('float'))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d264127e3f0450abbc0b9bceb7d65c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Id', 'float'), ('PostId', 'float'), ('Score', 'float'), ('CreationDate', 'string'), ('UserId', 'float'), ('SubDomain', 'string')]"
     ]
    }
   ],
   "source": [
    "# Checking column types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping NaNs and checking for our column data types, let's recount the number of rows to see if we dropped some rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fbaeee7ffb451c917fbea77477043e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16530530"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of rows is still 16,530,530, there are no NaN values in our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, we now have our working dataframe shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03568114cd434e0d97650e1d0927b3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+------+-----------+\n",
      "| Id|PostId|Score|        CreationDate|UserId|  SubDomain|\n",
      "+---+------+-----+--------------------+------+-----------+\n",
      "|1.0|  19.0|  0.0|2009-10-30T20:54:...|  24.0|electronics|\n",
      "|2.0|  19.0|  0.0|2009-10-30T21:18:...|  12.0|electronics|\n",
      "|3.0|  46.0|  0.0|2009-10-31T00:43:...|  24.0|electronics|\n",
      "|4.0|  46.0|  2.0|2009-11-01T02:25:...|  26.0|electronics|\n",
      "|5.0|  46.0|  1.0|2009-11-01T03:32:...|  26.0|electronics|\n",
      "+---+------+-----+--------------------+------+-----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Exploratory Data Analysis (EDA) stage will allow us to uncover the main characteristics of the dataset. Let us create a temporary SQL table to easily query the information that we want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1cdee7da814180a1ff55ad7d5ab7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Temporary SQL table\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf85c3fd85484f2c8c3fbef61a595b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique_Users\n",
      "0        247964"
     ]
    }
   ],
   "source": [
    "# Unique users\n",
    "spark.sql('''\n",
    "SELECT count(distinct(UserId)) as Unique_Users\n",
    "FROM df\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the total number of unique users, we see that there are about 248,000 users in StackExchange!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b5436c2a70411db516c5d6caf7b0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique_Subdomain\n",
      "0               162"
     ]
    }
   ],
   "source": [
    "# Unique subdomains\n",
    "spark.sql('''\n",
    "SELECT count(distinct(Subdomain)) as Unique_Subdomain\n",
    "FROM df\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the total number of unique subdomains, we see that there are 162 subdomains in StackExchange!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the distribution of comments per user across various subdomains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3632111e185948688f34ceb1ff2df55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserId  Presence_in_Subdomain\n",
      "0    92.0                     98\n",
      "1    13.0                     98\n",
      "2    29.0                     96\n",
      "3    43.0                     95\n",
      "4    38.0                     93\n",
      "5    44.0                     92\n",
      "6    36.0                     90\n",
      "7    69.0                     89\n",
      "8    10.0                     89\n",
      "9    20.0                     89"
     ]
    }
   ],
   "source": [
    "# Engagement of users across subdomains\n",
    "spark.sql('''\n",
    "SELECT UserId, count(distinct(SubDomain)) as Presence_in_Subdomain\n",
    "FROM df\n",
    "GROUP BY UserId\n",
    "ORDER BY Presence_in_Subdomain DESC\n",
    "LIMIT 10\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the top ten (10) users, we can see that they have commented across more than 89 subdomains, which is about half of the total subdomains in StackExchange. This means that these users have engaged in a wide array of subdomains. However, this does not mean that they are active users of each subdomain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef59e31ad3449b8c7c362ff3ca7765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Save csv to s3 bucket\n",
    "# spark.sql('''\n",
    "# SELECT UserId, count(distinct(SubDomain)) as Presence_in_Subdomain\n",
    "# FROM df\n",
    "# GROUP BY UserId\n",
    "# ORDER BY Presence_in_Subdomain DESC\n",
    "# ''').toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the count of unique users and comments of each subdomain to see which is most popular / active among users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef0bfc4dd0f4ff59c3c0ab1ab8efd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SubDomain  Unique_Users  Total_Comments\n",
      "0           unix         64806          675109\n",
      "1            tex         46862          877205\n",
      "2          stats         45311          526827\n",
      "3    electronics         42947          786504\n",
      "4          apple         42621          319778\n",
      "..           ...           ...             ...\n",
      "157    esperanto           276            4300\n",
      "158    ukrainian           271            5721\n",
      "159           or           216            1989\n",
      "160        tezos           192            1448\n",
      "161      conlang           171            1259\n",
      "\n",
      "[162 rows x 3 columns]"
     ]
    }
   ],
   "source": [
    "# Count of unique users and total comments per subdomain\n",
    "spark.sql('''\n",
    "SELECT SubDomain, count(distinct(UserId)) as Unique_Users,\n",
    "count(Id) as Total_Comments\n",
    "FROM df\n",
    "GROUP BY SubDomain\n",
    "ORDER BY Unique_Users DESC\n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular subdomain among users with 64,806 unique users is unix.stackexchange.com which is a subdomain for anything related to users of Linux, FreeBSD and other Unix-like operating systems. In contrast, the most commented subdomain is tex.stackexchange.com which is a subdomain for users of TeX, LaTeX, ConTeXt, and related typesetting systems.\n",
    "\n",
    "We can see that StackExchange is still mainly focused on technical people and is having trouble gaining users from non-technical subdomains such as conlang.stackexchange.com and ukrainian.stackexchange.com. This finding reinforces the value of this project by allowing users to discover new content that would suit their interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5fb39e8ffb44b09ae02d5e67529224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Save csv to s3 bucket\n",
    "# spark.sql('''\n",
    "# SELECT SubDomain, count(distinct(UserId)) as Unique_Users,\n",
    "# count(Id) as Total_Comments\n",
    "# FROM df\n",
    "# GROUP BY SubDomain\n",
    "# ORDER BY Unique_Users DESC\n",
    "# ''').toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will discuss the methods used in developing the recommender systems as well as the corresponding results and insights about the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Collaborative Filtering Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In creating a user-based collaborative filtering recommender system, our goal is to recommend suitable subdomains to a specific user. As mentioned in the introduction, this information would be very valuable for users in terms of content discovery as well as the owners of website, to generate more website traffic. PySpark provides a wonderful implementation of recommender systems using Alternating Least Squares (ALS). For this project, we will be using this library.\n",
    "\n",
    "The methodology in creating a user-based collaborative filtering recommender system is given below:\n",
    "1. Create numeriacl subdomain categories;\n",
    "2. Create subdomain mapping dictionary;\n",
    "3. Create uid, itemid, rating dataframe;\n",
    "4. Convert columns to float;\n",
    "5. Bin the ratings column;\n",
    "6. Split the dataset into train/test (80/20);\n",
    "7. Implement ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we pass the SubDomain column to the `StringIndexer` function to perform a one-hot encode of the column. This allows the computer to treat the variables as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5a25ec6d864f69bd638776aed9329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+------+-----------+--------------+\n",
      "| Id|PostId|Score|        CreationDate|UserId|  SubDomain|SubDomainIndex|\n",
      "+---+------+-----+--------------------+------+-----------+--------------+\n",
      "|1.0|  19.0|  0.0|2009-10-30T20:54:...|  24.0|electronics|           1.0|\n",
      "|2.0|  19.0|  0.0|2009-10-30T21:18:...|  12.0|electronics|           1.0|\n",
      "|3.0|  46.0|  0.0|2009-10-31T00:43:...|  24.0|electronics|           1.0|\n",
      "|4.0|  46.0|  2.0|2009-11-01T02:25:...|  26.0|electronics|           1.0|\n",
      "|5.0|  46.0|  1.0|2009-11-01T03:32:...|  26.0|electronics|           1.0|\n",
      "+---+------+-----+--------------------+------+-----------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Creating numerical subdomain categories\n",
    "indexer = StringIndexer(inputCol=\"SubDomain\", outputCol=\"SubDomainIndex\")\n",
    "df_indexed = indexer.fit(df)\n",
    "df = df_indexed.transform(df)\n",
    "df = df.withColumn('SubDomainIndex', df['SubDomainIndex'].astype('float'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's creating a mapping dictionary so we can later retrieve each subdomain after our system has recommended to a certain user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15db428079674124a8f9eadaba4e8a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating subdomain mapping dictionary\n",
    "subdomain_dict = {}\n",
    "\n",
    "for k, v in enumerate(df_indexed.labels):\n",
    "    subdomain_dict[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dictionary provides a mapping of all the subdomains to its specific index. The keys are the subdomain index while the values are its actual subdomain name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0b25216b8b4bbda0507168ac6e62f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'tex', 1: 'electronics', 2: 'english', 3: 'physics', 4: 'unix', 5: 'stats', 6: 'softwareengineering', 7: 'scifi', 8: 'worldbuilding', 9: 'gis', 10: 'mathematica', 11: 'apple', 12: 'wordpress', 13: 'gaming', 14: 'magento', 15: 'codegolf', 16: 'salesforce', 17: 'ell', 18: 'security', 19: 'codereview', 20: 'dba', 21: 'workplace', 22: 'academia', 23: 'travel', 24: 'drupal', 25: 'judaism', 26: 'diy', 27: 'sharepoint', 28: 'gamedev', 29: 'rpg', 30: 'puzzling', 31: 'blender', 32: 'ux', 33: 'android', 34: 'money', 35: 'photo', 36: 'cs', 37: 'aviation', 38: 'graphicdesign', 39: 'chemistry', 40: 'philosophy', 41: 'cooking', 42: 'raspberrypi', 43: 'bicycles', 44: 'webmasters', 45: 'skeptics', 46: 'politics', 47: 'history', 48: 'music', 49: 'crypto', 50: 'arduino', 51: 'german', 52: 'mechanics', 53: 'biology', 54: 'christianity', 55: 'movies', 56: 'space', 57: 'dsp', 58: 'japanese', 59: 'ethereum', 60: 'bitcoin', 61: 'hinduism', 62: 'emacs', 63: 'cstheory', 64: 'law', 65: 'writers', 66: 'webapps', 67: 'rus', 68: 'networkengineering', 69: 'linguistics', 70: 'softwarerecs', 71: 'french', 72: 'gardening', 73: 'boardgames', 74: 'quant', 75: 'parenting', 76: 'datascience', 77: 'hermeneutics', 78: 'astronomy', 79: 'scicomp', 80: 'spanish', 81: 'fitness', 82: 'chinese', 83: 'outdoors', 84: 'engineering', 85: 'islam', 86: 'anime', 87: 'sqa', 88: 'expressionengine', 89: 'buddhism', 90: 'retrocomputing', 91: 'interpersonal', 92: 'civicrm', 93: 'vi', 94: 'craftcms', 95: 'sound', 96: 'economics', 97: 'matheducators', 98: 'chess', 99: 'russian', 100: 'sitecore', 101: 'homebrew', 102: 'tridion', 103: 'pm', 104: 'earthscience', 105: 'cogsci', 106: 'reverseengineering', 107: 'joomla', 108: 'pets', 109: 'expatriates', 110: 'avp', 111: 'health', 112: 'robotics', 113: 'italian', 114: 'lifehacks', 115: 'woodworking', 116: 'ham', 117: 'latin', 118: 'opensource', 119: 'elementaryos', 120: 'ai', 121: '3dprinting', 122: 'portuguese', 123: 'sports', 124: 'genealogy', 125: 'hsm', 126: 'martialarts', 127: 'opendata', 128: 'tor', 129: 'hardwarerecs', 130: 'patents', 131: 'windowsphone', 132: 'bioinformatics', 133: 'literature', 134: 'computergraphics', 135: 'cseducators', 136: 'bricks', 137: 'sustainability', 138: 'devops', 139: 'poker', 140: 'monero', 141: 'quantumcomputing', 142: 'freelancing', 143: 'ukrainian', 144: 'musicfans', 145: 'iot', 146: 'crafts', 147: 'mythology', 148: 'esperanto', 149: 'coffee', 150: 'korean', 151: 'eosio', 152: 'languagelearning', 153: 'ebooks', 154: 'beer', 155: 'vegetarianism', 156: 'iota', 157: 'or', 158: 'stellar', 159: 'moderators', 160: 'tezos', 161: 'conlang'}"
     ]
    }
   ],
   "source": [
    "subdomain_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PySpark ALS function only allows as input a spark DataFrame with the following schema -- uid, itemid, rating (count). As such, we create a spark DataFrame to be able to develop our recommender system. This is equivalent to creating our utility matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d149e7ec78e4a59877be0d37e5153fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----+\n",
      "| UserId|SubDomainIndex|count|\n",
      "+-------+--------------+-----+\n",
      "|   77.0|           2.0| 1075|\n",
      "| 8843.0|           2.0|    2|\n",
      "| 8293.0|           2.0|    2|\n",
      "|10117.0|           2.0|    1|\n",
      "|11007.0|           2.0|  146|\n",
      "+-------+--------------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Creating uid, itemid, rating (count) dataframe\n",
    "df_rs = spark.createDataFrame(df.groupby(['UserId', 'SubDomainIndex']).count().collect())\n",
    "df_rs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to remove users with only one (1) subdomain visited or commented on, we can run the code below. The reason for this is that users who have commented only once in a subdomain may just be added noise during the training of our recommender system. However, for the final recommender system, we left it as such since it generates a better evaluation metric score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2298476ee24d6fae654a0cca6abf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN IF YOU WANT TO REMOVE ALL USERS WITH ONLY 1 SUBDOMAIN VISITED!\n",
    "\n",
    "# # Selecting users with only 1 subdomain visited\n",
    "# df_rs2 = (df_rs.groupby('UserId')\n",
    "#           .agg(collect_set('SubDomainIndex').alias('trans'))\n",
    "#           .where(size(col('trans')) == 1)\n",
    "#           .select('UserId'))\n",
    "\n",
    "# # Removing users with only 1 subdomain visited\n",
    "# df_rs3 = df_rs.join(\n",
    "#     df_rs2, \n",
    "#     [df_rs.UserId == df_rs2.UserId], \n",
    "#     how='left_anti'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the PySpark ALS function only takes as an input a spark DataFrame. In addition, it requires that all fields should be of float type. As such, we convert all fields to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9d4397e41f4f2c91a54a0e3b12e7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converting UserId, SubDomainIndex to float\n",
    "df_rs = df_rs.withColumn('UserId', df_rs['UserId'].astype('float'))\n",
    "df_rs = df_rs.withColumn('SubDomainIndex', df_rs['SubDomainIndex'].astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have the option of scaling the rating (count) column if we run the code below. However, similar with removing users with only one (1) subdomain visited, we chose to leave it as such for the final recommender system since it produces a better recommender system performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3d338bf22e4be1b9ecc30c6e30f547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scaling counts per subdomain\n",
    "# w = Window.partitionBy(\"SubDomainIndex\")\n",
    "\n",
    "# scaled_result = (col(\"count\") - min(\"count\").over(w)) / (max(\"count\").over(w) - min(\"count\").over(w))\n",
    "\n",
    "# df_rs = df_rs.withColumn(\"count_scaled\", scaled_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having the raw comment counts as ratings may affect the accuracy of our recommender system due to its continuous nature. In order to solve this, we decided to arbitrarily bin the ratings (count) column into five discrete categories. Comment counts between 1-10 will have an engagement score of 1.0, 10-100 will be equal to 2.0, 100-500 will be 3.0, 500-1000 is 4.0, and 1000 and above will have a perfect rating of 5.0. This binning will hopefully capture the engagement of each user for each subdomain better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a9d10d5ec84a69b0cda89e19d0be79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Binning (franco-defined)\n",
    "bucketizer = Bucketizer(splits=[1, 10, 100, 500, 1000, float(\"inf\")],\n",
    "                        inputCol=\"count\", outputCol=\"rating\")\n",
    "bucketed = bucketizer.setHandleInvalid(\"keep\").transform(df_rs)\n",
    "bucketed = bucketed.withColumn('rating', bucketed['rating'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distinct ratings we created below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e8ad7c3e994fb0af96b74128a68460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|   1.0|\n",
      "|   4.0|\n",
      "|   3.0|\n",
      "|   2.0|\n",
      "|   5.0|\n",
      "+------+"
     ]
    }
   ],
   "source": [
    "# Distinct ratings\n",
    "bucketed.select('rating').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e33f8ca83c4f18b8b9fc391d111bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rs = bucketed.drop('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our recommender system, we split the data into two (2). The splitting is done with a ratio of 80/20 for train test and test set respectively. The ALS algorithm attempts to estimate the ratings matrix R as the product of two lower-rank matrices, X and Y, i.e. X * Yt = R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f1546c4b2b46f185ad3e981c74a902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train/test split\n",
    "df_training, df_test = df_rs.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit our ALS algorithm to the training set. The function takes the following parameters:\n",
    "- **maxIter** - number of ALS iterations to use\n",
    "- **regParam** - regularization parameter\n",
    "- **userCol** - user column\n",
    "- **itemCol** - item column\n",
    "- **ratingCol** - rating column\n",
    "- **coldStartStrategy** - strategy for dealing with unknown or new users/items at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa8e806030a40358e8cad78dbbc7193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ALS\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"UserId\", itemCol=\"SubDomainIndex\", \n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "als_trained = als.fit(df_training)\n",
    "df_predict = als_trained.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then save the results by running the following code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba02ab84f3d64d198f71e58cb4af3004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_predict.toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/testsetpredictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate our recommender system by testing it on our test set. With this, we obtained a Root-mean-square error (RMSE) of 0.64. This value is relative to the set rating of 1 to 5 which means that the results are fairly acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c1317f704546fc818197410e0357b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE) = 0.631530670539948"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(df_predict)\n",
    "print(\"Root-mean-square error (RMSE) = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our recommender system created, let's try to make ten (10) subdomain recommendations to 20 users of StackExchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4add5b3818bd4551ada04ca5a55d8bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make recommendation\n",
    "users = df_rs.select(als.getUserCol()).distinct().limit(20) # Limit to 20 users only\n",
    "df_recomm = als_trained.recommendForUserSubset(users, 5) # Recommend 10 subdomains to 20 users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dataframe below, we can see that our recommender system was able to recommend subdomains for 20 users. The dataframe shows the recommendations as a tuple of (subdomain index, rating). However, a dataframe form is not the best way to visualize the recommendations offered to us by the system as it cuts off the succeeding recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db09315571c42c3976ece660e6362a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserId|     recommendations|\n",
      "+------+--------------------+\n",
      "|151313|[[54, 1.4390156],...|\n",
      "| 46216|[[80, 2.7420862],...|\n",
      "|158615|[[58, 1.3765002],...|\n",
      "|199107|[[89, 1.4872445],...|\n",
      "| 40068|[[29, 3.4181402],...|\n",
      "|174591|[[61, 3.1779935],...|\n",
      "| 53788|[[15, 1.0364293],...|\n",
      "| 87436|[[89, 2.1108139],...|\n",
      "| 49045|[[2, 1.0462611], ...|\n",
      "| 94226|[[58, 1.1530683],...|\n",
      "|106426|[[58, 2.440846], ...|\n",
      "|234576|[[4, 0.9703308], ...|\n",
      "|251851|[[89, 1.1534979],...|\n",
      "| 73847|[[143, 1.072845],...|\n",
      "|111682|[[54, 1.2653142],...|\n",
      "| 42656|[[14, 2.642518], ...|\n",
      "|  2976|[[51, 2.00029], [...|\n",
      "|174463|[[58, 1.259797], ...|\n",
      "|166559|[[77, 1.1249527],...|\n",
      "|  4618|[[16, 2.9131286],...|\n",
      "+------+--------------------+"
     ]
    }
   ],
   "source": [
    "df_recomm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56703a53ad8b40749a14c113c076f7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_recomm.toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/samplerecomm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can try to single out one (1) user and print out the recommended subdomains using the subdomain mapping dictionary we created earlier. Let's try to recommend five (5) subdomains for user 40124."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f5b97a80144eaa4d75fa87cce0119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting user 40124.0\n",
    "users2 = df_rs.filter(df_rs['UserId'] == 40124.0 ).distinct().select('UserId').limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e295a4e88f944c37bf02013a6052da5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating recommender for prof alis\n",
    "df_recomm2 = als_trained.recommendForUserSubset(users2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the array below, we can see the recommended subdomain indices and its corresponding rating for user 40124. The recommendations are arranged by decreasing rating already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e1c6fb5d47428b8ec66ee08f5c31d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([list([Row(SubDomainIndex=29, rating=2.0890419483184814), Row(SubDomainIndex=69, rating=2.0499415397644043), Row(SubDomainIndex=75, rating=1.9870492219924927), Row(SubDomainIndex=98, rating=1.9799880981445312), Row(SubDomainIndex=37, rating=1.9656609296798706)])],\n",
      "      dtype=object)"
     ]
    }
   ],
   "source": [
    "# Getting recommended items\n",
    "df_recomm2.toPandas()['recommendations'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to identify which subdomains were recommended to us by accessing the look-up dictionary we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc05e88f90b54f8dae99591ef221cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpg\n",
      "linguistics\n",
      "parenting\n",
      "chess\n",
      "aviation"
     ]
    }
   ],
   "source": [
    "# Look-up recommended ids\n",
    "print(subdomain_dict[29])\n",
    "print(subdomain_dict[69])\n",
    "print(subdomain_dict[75])\n",
    "print(subdomain_dict[98])\n",
    "print(subdomain_dict[37])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our system has recommended specific subdomains that our user may be interested in based on the interests of other users that are similar to him."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Itemset Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we were able to create a user-specific recommender system for StackExchange, we would also like to identify frequent itemsets of subdomains, or subdomains commonly visited together by many users. It is also in our interest to create association rules between them to suggest possible subdomain collaborations. For this part of the project, we will be using FP-growth algorithm to implement FIM for the reason that it does not require the generation of a candidate itemset. Instead, it uses projected databases by scanning the subset of the database that contains the prefix of the itemsets and with the prefix removed from the values. This generally translates to a faster run-time.\n",
    "\n",
    "The methodology to identify frequent itemsets and create association rules of artists is given below:\n",
    "1. Create horizontal transactional database;\n",
    "2. Create frequent itemsets via FP-growth;\n",
    "3. Create association rules (confidence, lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the original dataframe that we have from the comments.xml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af26bc77b44f4a92ab859297a652b9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+------+-----------+--------------+\n",
      "| Id|PostId|Score|        CreationDate|UserId|  SubDomain|SubDomainIndex|\n",
      "+---+------+-----+--------------------+------+-----------+--------------+\n",
      "|1.0|  19.0|  0.0|2009-10-30T20:54:...|  24.0|electronics|           1.0|\n",
      "|2.0|  19.0|  0.0|2009-10-30T21:18:...|  12.0|electronics|           1.0|\n",
      "|3.0|  46.0|  0.0|2009-10-31T00:43:...|  24.0|electronics|           1.0|\n",
      "|4.0|  46.0|  2.0|2009-11-01T02:25:...|  26.0|electronics|           1.0|\n",
      "|5.0|  46.0|  1.0|2009-11-01T03:32:...|  26.0|electronics|           1.0|\n",
      "+---+------+-----+--------------------+------+-----------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a horizontal database by grouping the dataframe according to UserId and then getting all the unique subdomains that a unique user has visited. In the following cell, we do so and then train the FP-growth algorithm as well to the horizontal database that we just created with the following hyperparameters:\n",
    "\n",
    "- $minSupport = 0.01$\n",
    "- $minConfidence = 0.01$\n",
    "\n",
    "Setting $minSupport = 0.01$ means that we are getting only the itemsets with a relative support equal to $0.01%$. Relative support is defined as the fraction of transactions having $X$ as a subset,\n",
    "$$\n",
    "relSup(X) = \\frac{sup(X)}{N}.\n",
    "$$\n",
    "\n",
    "Setting $minConfidence = 0.01$ sets the minimum confidence for generating an Association Rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac4956aca364c28b5850bee82afd70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_trans = (df.groupby('UserId')\n",
    "                     .agg(collect_set('SubDomain').alias('trans'))\n",
    "                     .cache())\n",
    "\n",
    "fpgrowth = FPGrowth(itemsCol=\"trans\", minSupport=0.01, minConfidence=0.01)\n",
    "fpgrowth_trained = fpgrowth.fit(df_trans)\n",
    "\n",
    "# print('Frequent itemsets:')\n",
    "df_fim = fpgrowth_trained.freqItemsets.orderBy('freq', ascending=False)\n",
    "\n",
    "# print('Association rules:')\n",
    "df_ar = fpgrowth_trained.associationRules\n",
    "\n",
    "# print('Consequents from association rules:')\n",
    "df_car = fpgrowth_trained.transform(df_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is the horizontal database that we have created which contains all the unique subdomains each unique user has commented on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b5d5ce43f7402a931c93084807c40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserId|               trans|\n",
      "+------+--------------------+\n",
      "| 714.0|[fitness, network...|\n",
      "|1033.0|[mathematica, hea...|\n",
      "|1575.0|[webapps, mechani...|\n",
      "|2077.0|[ai, networkengin...|\n",
      "|2098.0|[parenting, mathe...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df_trans.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at its count, there are 247,964 unique users in total -- consistent with our finding during the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c81fb8cc884c0d846dc5693df45c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247964"
     ]
    }
   ],
   "source": [
    "df_trans.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to find a total of 573 frequent itemsets, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fedd08c881946a78343c904568709a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573"
     ]
    }
   ],
   "source": [
    "df_fim.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most frequent itemsets are only 1-itemsets and 2-itemsets. With this knowledge, we can see which subdomains are commonly visited together by different users. We can then try to encourage interaction between the frequent-itemset subdomains to improve community engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d2efa485ad400fae16e6ff6b10cd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        items   freq\n",
      "0                      [unix]  64806\n",
      "1                       [tex]  46862\n",
      "2                     [stats]  45311\n",
      "3               [electronics]  42947\n",
      "4                     [apple]  42621\n",
      "..                        ...    ...\n",
      "568          [ethereum, unix]   2498\n",
      "569     [mathematica, travel]   2497\n",
      "570       [webmasters, scifi]   2492\n",
      "571            [photo, stats]   2492\n",
      "572  [webmasters, salesforce]   2483\n",
      "\n",
      "[573 rows x 2 columns]"
     ]
    }
   ],
   "source": [
    "df_fim.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0303d8210f5d4121953034793c6e636a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving fim results to csv\n",
    "# df_fim.toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/fimresults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790326e4142e4c0693a2560ad1fcaf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fimpandas = df_fim.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, getting only 2-itemsets, we see a better look at which subdomains are commonly visited. We can see that tex and unix top the chart with 11,156 visits from unique users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a60b2597ad48d78202e41b851496e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        items   freq  len(items)\n",
      "36                [tex, unix]  11156           2\n",
      "38              [stats, unix]   9966           2\n",
      "40               [stats, tex]   9460           2\n",
      "42        [electronics, unix]   9251           2\n",
      "43         [electronics, tex]   9154           2\n",
      "..                        ...    ...         ...\n",
      "568          [ethereum, unix]   2498           2\n",
      "569     [mathematica, travel]   2497           2\n",
      "570            [photo, stats]   2492           2\n",
      "571       [webmasters, scifi]   2492           2\n",
      "572  [webmasters, salesforce]   2483           2\n",
      "\n",
      "[482 rows x 3 columns]"
     ]
    }
   ],
   "source": [
    "# Getting only fim with more than 2 items\n",
    "df_fimpandas['len(items)'] = df_fimpandas['items'].apply(lambda x: len(x))\n",
    "df_fimpandas[df_fimpandas['len(items)'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also shows that users mostly visit only 2 subdomains rather than more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mentioned hyperparameter values were decided based on the variety of items between itemsets and the number of itemsets returned by the algorithm. We wanted to get enough itemsets which vary from each other quite well. In this case, we got the best result using the mentioned hyperparameters.\n",
    "\n",
    "The insights that can be gathered from the frequent itemset analysis is limited in the sense that it only provides the set of subdomains which are frequently visited together. It does not provide associations between a subdomain and a set of subdomains. To create this association, we perform association rule mining. The association between subdomains and the sets of subdomains is measured by $confidence$ and $lift$.\n",
    "\n",
    "$Confidence$ refers to the likelihood that subdomain B is also visited if subdomain A is visited. <br>\n",
    "$Lift$ refers to the increase in the ratio of visits of B when A is visited. Here are the general rules of thumb for the $Lift$ value:\n",
    "- $Lift = 1$ means no association between artists A and B. \n",
    "- $Lift > 1$ means products A and B are more likely to be associated with each other. \n",
    "- $Lift < 1$ means products A and B are unlikely to be associated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this knowledge, we find that there are a total of 964 association rules created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be001cfe95f4a43a26681924551778a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964"
     ]
    }
   ],
   "source": [
    "df_ar.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering all of these association rules by decreasing confidence, we see that biology will most likely be visited if a user visits the subdomain tex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d945b3bd1dd4854bbfad5d88fc5ed02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-------------------+------------------+\n",
      "|     antecedent|consequent|         confidence|              lift|\n",
      "+---------------+----------+-------------------+------------------+\n",
      "|      [biology]|     [tex]| 0.3612705191512078|1.9116145920107996|\n",
      "|          [dsp]|     [tex]| 0.3605310468814825|1.9077017734821378|\n",
      "|    [mechanics]|     [tex]| 0.3585034789551728|1.8969731692125917|\n",
      "|     [puzzling]|     [tex]|0.35273626250140466|1.8664567153535554|\n",
      "| [softwarerecs]|     [tex]| 0.3459727700725283|1.8306686005348558|\n",
      "|     [ethereum]|     [tex]|0.34062068099007414|1.8023487375917107|\n",
      "|[worldbuilding]|     [tex]|0.33345642540620385|1.7644400381849672|\n",
      "|       [crypto]|     [tex]|0.33200047042220393|1.7567360472829026|\n",
      "|          [rpg]|     [tex]| 0.3319880073800738|1.7566701007637877|\n",
      "|      [cooking]|     [tex]|  0.325875260839323|1.7243253207025286|\n",
      "|    [chemistry]|     [tex]|0.32541069556099267| 1.721867135719474|\n",
      "|  [mathematica]|     [tex]| 0.3226930186264752|1.7074869120117644|\n",
      "|       [drupal]|     [tex]| 0.3217949566483553|1.7027349372701288|\n",
      "|      [arduino]|     [tex]|  0.321482439129498|1.7010812926530416|\n",
      "|      [magento]|     [tex]|0.31873129173382453|1.6865239644805188|\n",
      "|     [codegolf]|     [tex]|0.31816096173258696|1.6835061396239852|\n",
      "|   [salesforce]|     [tex]|0.31646932185145316|1.6745550536377818|\n",
      "|          [ell]|     [tex]| 0.3158470799781096|1.6712625440589812|\n",
      "|        [photo]|     [tex]|0.31448940656692437|1.6640785969433836|\n",
      "|     [ethereum]|    [unix]|0.31385852494031913|1.2009013868824074|\n",
      "+---------------+----------+-------------------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_ar.orderBy('confidence', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering the association rules by decreasing lift, we can see that worldbuilding and mathematica are most associated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17919583eef451fb26417588b74c6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-------------------+------------------+\n",
      "|     antecedent|     consequent|         confidence|              lift|\n",
      "+---------------+---------------+-------------------+------------------+\n",
      "|[worldbuilding]|  [mathematica]|0.22119645494830134|3.8993855932603867|\n",
      "|  [mathematica]|[worldbuilding]| 0.2129247831650789| 3.899385593260386|\n",
      "|   [salesforce]|[worldbuilding]|0.20217818020642056| 3.702578306994451|\n",
      "|[worldbuilding]|   [salesforce]|0.23581979320531757|3.7025783069944507|\n",
      "|   [salesforce]|  [mathematica]|0.20015196606091307|3.5284005482957665|\n",
      "|  [mathematica]|   [salesforce]|  0.224726290345514|3.5284005482957657|\n",
      "|       [drupal]|[worldbuilding]|  0.182606393540274| 3.344151533812445|\n",
      "|[worldbuilding]|       [drupal]| 0.2037666174298375|3.3441515338124446|\n",
      "|      [blender]|  [mathematica]| 0.1843353955192504| 3.249576426456378|\n",
      "|  [mathematica]|      [blender]|0.21818569600454998| 3.249576426456378|\n",
      "|       [drupal]|  [mathematica]|0.18412866503408565|3.2459320557736397|\n",
      "|  [mathematica]|       [drupal]| 0.1977818853974122|3.2459320557736393|\n",
      "|[worldbuilding]|      [blender]|0.21499261447562776|   3.2020198604021|\n",
      "|      [blender]|[worldbuilding]| 0.1748453360562196|   3.2020198604021|\n",
      "|      [magento]|[worldbuilding]|0.17395809348376698|3.1857713953182274|\n",
      "|[worldbuilding]|      [magento]|0.22319054652880355| 3.185771395318227|\n",
      "|[worldbuilding]|   [sharepoint]|0.21129985228951256| 3.141360787404323|\n",
      "|   [sharepoint]|[worldbuilding]|0.17153306553150668|3.1413607874043223|\n",
      "|   [salesforce]|       [drupal]| 0.1909073640220351| 3.133109644077034|\n",
      "|       [drupal]|   [salesforce]|0.19954993712356872|3.1331096440770336|\n",
      "+---------------+---------------+-------------------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_ar.orderBy('lift', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b088fdb5a0427f93e1168d9fc61007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving ar to csv\n",
    "# df_ar.toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/arresults.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a recommender system for each user, using only the frequent-itemsets and association rules that we have created by collecting all the subdomains visited by a user, and then gathering all those subdomains that are associated with it. The downside of this though, is that there is no immediate ranking on which subdomain to recommend to a certain user. We can only make this recommendation as a bulk recommendation to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is a dataframe of recommendations, tagged in the column named prediction fo each unique user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864be19670764b1fa6f6370878b432ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|UserId|               trans|          prediction|\n",
      "+------+--------------------+--------------------+\n",
      "| 714.0|[fitness, network...|[unix, dba, stats...|\n",
      "|1033.0|[mathematica, hea...|[tex, codereview,...|\n",
      "|1575.0|[webapps, mechani...|[tex, codereview,...|\n",
      "|2077.0|[ai, networkengin...|[codereview, dba,...|\n",
      "|2098.0|[parenting, mathe...|[tex, travel, sal...|\n",
      "+------+--------------------+--------------------+"
     ]
    }
   ],
   "source": [
    "df_car.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ece1a3a18524cfbbf92aad2ca1afba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save car to csv\n",
    "# df_car.toPandas().to_csv('s3://bdcc-rrivera-2020/stackexchange/eda/carresults.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the recommendations for user 714 based on the frequent-itemsets and association rules that we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cc16e912ce49a4ba6e453f37a8d7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unix', 'dba', 'stats', 'english', 'softwareengineering', 'wordpress', 'electronics', 'physics', 'mathematica', 'blender', 'sharepoint', 'gamedev', 'salesforce', 'diy', 'gaming', 'scifi', 'workplace', 'ux', 'webmasters', 'money', 'travel', 'raspberrypi', 'cs', 'academia', 'graphicdesign', 'ell', 'codegolf', 'puzzling', 'chemistry', 'webapps', 'photo', 'arduino', 'mechanics', 'bitcoin', 'biology']"
     ]
    }
   ],
   "source": [
    "df_car.limit(5).toPandas().iloc[0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe our user can hand-pick some of the interesting subdomains that he/she may see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we were able to wrangle Big Data and create two (2) implementations of recommender systems for StackExchange.\n",
    "The first is through the use of a user-based collaborative filtering algorithm and the second is by using frequent-itemsets and association rules.\n",
    "\n",
    "The first approach is more promising since it takes into account explicit ratings from each user. This allows us to recommend subdomains that a similar user would like. Thus, this approach is focused more towards the user. The second approach can be thought of as more owner-focused since it identifies the commonly visited subdomains and its associations. This could help the owners of StackExchange identify strong collaborations between subdomains, to encourage interaction and community engagement.\n",
    "\n",
    "Some of the team's insights were:\n",
    "- The big volume of user interaction with the website helped uncover subdomains frequently visited together; and\n",
    "- A user-specific recommendation depends on browsing patterns of other users\n",
    "\n",
    "With our findings, the team would like to recommend to the owners of StackExchange to:\n",
    "- Place related subdomain links in the recommendation panes or conspicuous parts of the website; and\n",
    "- Incentivize user engagement deeper into or across more subdomains\n",
    "\n",
    "This approach or methodology is not only applicable to StackExchange, this could also be used to various platforms such as e-commerce platforms, social media platforms and literally any platform that has a rich database of user-item transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Acknowledgment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Pdfs.semanticscholar.org. (2019). Available at: https://pdfs.semanticscholar.org/fb3a/fca3dcdc1d9d786fd56c3132f327caff111e.pdf. <br>\n",
    "[2] Stack Abuse. (2019). Association Rule Mining via Apriori Algorithm in Python. Available at: https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/. <br>\n",
    "[3] Medium. (2019). Building and Testing Recommender Systems With Surprise, Step-By-Step. Available at: https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to acknowledge Prof. Christian Alis for his lessons and guidance during the whole course of Big Data and Cloud Computing (BDCC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
